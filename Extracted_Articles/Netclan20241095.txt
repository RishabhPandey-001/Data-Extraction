An ETL Solution for Currency Data to Google Big Query

Client: A Leading Tech Firm in the USA Industry Type: IT Consulting Services: Software, Consulting Organization Size: 100+ Fetch currency data from Pure-clear API and store it to Google cloud BigQuery. Create a Google cloud function to automate the above process. We have given a pure-clear API and a google cloud account. We need to fetch currency data from that pure-clear API using python and need to store fetched data in Google Cloud Bigquery. We also need to automate the above process like the process runs on a daily basis and update the currency data on Bigquery. We have created a python program that can fetch pure-clear API data. The API data was in JSON format but we needed table format so we used python package pandas. We converted json data to tabular format using pandas. After that, we connected python code to google cloud using google’s authentication module and then stored data frame (table) directly to BigQuery using the “.to_gbq” method. We also need to run the above process daily to update new data in BigQuery. For this Google cloud provides a “Cloud function” tool. In this, we can create a function and set up their running process. So we created a function and attached the above code to that function and set up a cloud function to run daily. A Google cloud function that runs daily and updates data on Google BigQuery Cloud function, BigQuery of Google Cloud, Google Colab notebook, Python programming, Pandas Python language and pandas module Python programming, Data handling, Google Cloud Google Cloud BigQuery Google Cloud Server Connecting google cloud to python code is challenging because Its credentials should be in a specified format otherwise it shows an authentication error. To tackle this challenge we created a dictionary format (key-value pair) and stored all the authentication variables in the dictionary as a key value pair. Then we used google’s authentication library “google.auth” and passed a dictionary to the service_account method and stored it in different variables so we can store data from pandas dataframe to Google BigQuery. Transforming Real Estate Investments with an Automated Stack shares Platform Empowering Careers: The Hirekingdom Integrating Machine Learning Code into Kubeflow Pipeline – Kuberflow MLOps Kubernetes What patients like and dislike about telemedicine? Data ETL: Local Service Ads Leads to BigQuery Portfolio: Website, Dashboard, SaaS Applications, Web Apps Streamlining Time Calculation in Warehouse Management: Leveraging ShipHero API and Google... What are the key policies that will mitigate the impacts of... Turning the Professional Networking Data into Actionable Insights Pharmaceutical Data Power BI Report On-Page SEO