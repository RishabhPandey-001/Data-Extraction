Optimize the data scraper program to easily accommodate large files and solve OOM errors

Client: A leading tech firm in India Industry Type: IT Services Services: SAAS services, Marketing services, Business consultant Organization Size: 100+ Building a large data warehouse that houses projects and tenders data from all over the world that is to be collected from official government websites, multilateral banks, state and local government agencies, data aggregating websites, etc. We had tried multiple solutions to prevent the program from running out of memory. We used python pandas techniques to control the use of memory which worked for some files and did not work for others. Provided more solutions using vaex ,dask module and datatables. Desired changes to the code and committing them to github. Vscode Python Github Slack Chunking dask Dataframe vaex datatable python. Cloud Python Time complexity System specs requirement was the main issue during this project because the RAM available was too less and got used up quickly. Team viewer to use remote desktop which had higher specs would be sufficient enough to solve the problem. Provided various techniques to solve memory issues. Suggested parallel programming to decrease the execution time by 12% making getting the tender data at a much faster rate. https://github.com/Taiyo-ai/opentenders-eu https://opentender.eu  Transforming Real Estate Investments with an Automated Stack shares Platform Empowering Careers: The Hirekingdom Integrating Machine Learning Code into Kubeflow Pipeline – Kuberflow MLOps Kubernetes Predictive Modelling, AI, ML Dashboards in Power BI Get Answers from Structural Equation Modeling How big data and analytics is shaping tomorrow for marketing leaders? How Coronavirus Impact on the Hospitality Industry Networking Platform – Have a look How to Setup Custom Domain for Google App Engine Application? GPT/OCR API Off-Page SEO