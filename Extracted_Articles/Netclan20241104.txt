Data integration and big data performance using Elasticsearch

Client: A Leading Tech Firm in the USA Industry Type: IT & Consulting Services: Software, Business Solutions, Consulting Organization Size: 200+ Migrate existing databases from Postgres to elastic search since Elasticserach performs better in search operations. In addition to this, all of the backend javascript also needed to be changed in order to query the new elasticsearch database. The client’s website was a visualization tool. It also had GUI to add filters. To make the visualizations, at least 50,000 records needed to be pulled from the Postgres database whose size would be around 200mbs. This would take a lot of time (nearly 20-30 secs). Adding filters would take additional time. So our task was to move the entire database over to Elasticsearch from postgres since it is way more faster in search operations and also filtering data. Since the database was changed, we also had to write new backend code that would now query the Elasticsearch database. Setup ELK stack (Elasticsearch, Logstash, Kibana) on AWS EC2 instance. Write a pipeline file (.conf file) which is used to ingest data from postgres to elasticsearch. The datatypes of cloumns, unique constraints, datetime formats etc., are all defined in this file. This is executed with the help of logstash. Once the data is inserted, it can be queried in the kibana’s built in query compiler. Here we can check the veracity of the data. Identify the code in the backend that needs to be changed. Replace this code with new code that would now query elasticserach. We use elastic_query_builder module for this. Testing Postgres and Elasticsearch performance. Setup ELK stack (Elasticsearch, Logstash, Kibana) on AWS EC2 instance. Pipeline i.e; logstash file New working backend code for elasticsearch Commands to check elastic data. Customizable logstash pipeline Elasticsearch Postman Kibana Logstash Python Javascript Amazon Web Services Postgres Docker Git Bucket Github Javascript Json Domain-Specific Language for elasticsearch bash Elasticsearch query knowledge Postgres query knowledge Networking Javascript Backend web stack Postgres Elasticsearch Amazon Web Services (AWS) Sometimes for large responses from elasticsearch ( size above 500mb), time taken was above 30 secs. To solve the above mentioned problem, we used gzip in the request url’s header. This significantly reduced the execution times. Earlier postgres infrastructure which took around 20-30 secs now too consistently less than 10 secs to perform filter and search operations. This would contribute to a better user experience. Transforming Real Estate Investments with an Automated Stack shares Platform Empowering Careers: The Hirekingdom Integrating Machine Learning Code into Kubeflow Pipeline – Kuberflow MLOps Kubernetes Efficient Database Design and Management: Streamlining Access and Integration for Partner... AI tools and software for Electrical Engineering, categorized based on their... Recommendation System Architecture Contribution of handicrafts (Visual Arts & Literature) in the Indian economy What if the Creation is Taking Over the Creator? Impact of COVID-19 pandemic on entertainment industries such as theaters. MetaBridges API Decentraland Integration – AR, VR Data from CRM via Zapier to Google Sheets (Dynamic) to PowerBI